{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('saved_variables/X_y_train_test.pickle', 'rb') as open_pickle_file:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(open_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "[ 1  3  5  7  9 11 13 15 17 19 21 23 25 27 29]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48\n",
      " 50 52 54 56 58]\n",
      "[0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45]\n"
     ]
    }
   ],
   "source": [
    "#cp_alpha_list = np.arange(.000,.035,.002)\n",
    "#rint(ccp_alpha_list)\n",
    "#rint(len(ccp_alpha_list))\n",
    "\n",
    "min_impurity_decrease_list = np.arange(0,1,.1)\n",
    "\n",
    "#mean impuirty split messes up model with alteration\n",
    "\n",
    "min_samples_leaf_list = np.arange(1,30,2)\n",
    "min_samples_split_list = np.arange(2,60,2)\n",
    "min_weight_fraction_leaf_list = np.arange(0.0, .5, .05)\n",
    "\n",
    "print(min_impurity_decrease_list)\n",
    "print(min_samples_leaf_list)\n",
    "print(min_samples_split_list)\n",
    "print(min_weight_fraction_leaf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43500"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def expand_grid(dct):\n",
    "    rows = itertools.product(*dct.values())\n",
    "    return pd.DataFrame.from_records(rows, columns=dct.keys())\n",
    "\n",
    "\n",
    "df = expand_grid(\n",
    "    {'min_impurity_decrease': min_impurity_decrease_list,\n",
    "     'min_samples_leaf': min_samples_leaf_list,\n",
    "     'min_samples_split': min_samples_split_list,\n",
    "    'min_weight_fraction_leaf': min_weight_fraction_leaf_list})\n",
    "range(0,len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(list_a,new_item):\n",
    "    list_a.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for i in range(0,len(df)):\n",
    "    clf = DecisionTreeClassifier(random_state=0, \n",
    "                                 min_impurity_decrease=df['min_impurity_decrease'][i],\n",
    "                                 min_samples_leaf=df['min_samples_leaf'][i], \n",
    "                                 min_samples_split=df['min_samples_split'][i], \n",
    "                                 min_weight_fraction_leaf=df['min_weight_fraction_leaf'][i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print(clf)\n",
    "    add_to_list(clfs,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=30, min_samples_split=60,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing tree\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, random_state=0, splitter='best',\n",
    "                       ccp_alpha=0.0,\n",
    "                       class_weight=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_impurity_split=None,\n",
    "                       min_samples_leaf=30,\n",
    "                       min_samples_split=60,\n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       presort='deprecated')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-0dc8ab455c3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#test_scoress = clf.score(X_test, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(train_scoress)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "#train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "#train_scoress = clf.score(X_train, y_train)\n",
    "#test_scoress = clf.score(X_test, y_test)\n",
    "#print(train_scoress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "6        False\n",
       "7        False\n",
       "8        False\n",
       "9        False\n",
       "10       False\n",
       "11        True\n",
       "12       False\n",
       "13       False\n",
       "14       False\n",
       "15       False\n",
       "16       False\n",
       "17       False\n",
       "18       False\n",
       "19       False\n",
       "20        True\n",
       "21        True\n",
       "22       False\n",
       "23       False\n",
       "24       False\n",
       "25       False\n",
       "26       False\n",
       "27       False\n",
       "28       False\n",
       "29       False\n",
       "         ...  \n",
       "43470    False\n",
       "43471    False\n",
       "43472    False\n",
       "43473    False\n",
       "43474    False\n",
       "43475    False\n",
       "43476    False\n",
       "43477    False\n",
       "43478    False\n",
       "43479    False\n",
       "43480    False\n",
       "43481    False\n",
       "43482    False\n",
       "43483    False\n",
       "43484    False\n",
       "43485    False\n",
       "43486    False\n",
       "43487    False\n",
       "43488    False\n",
       "43489    False\n",
       "43490    False\n",
       "43491    False\n",
       "43492    False\n",
       "43493    False\n",
       "43494    False\n",
       "43495    False\n",
       "43496    False\n",
       "43497    False\n",
       "43498    False\n",
       "43499    False\n",
       "Name: test_scores, Length: 43500, dtype: bool"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['test_scores'] = test_scores\n",
    "new_df = df['test_scores'] >.90\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.726984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.122359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.629371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.629371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.629371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  43500.000000\n",
       "mean       0.726984\n",
       "std        0.122359\n",
       "min        0.629371\n",
       "25%        0.629371\n",
       "50%        0.629371\n",
       "75%        0.881119\n",
       "max        0.937063"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame(test_scores)\n",
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-ad2bc9d0044c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-ad2bc9d0044c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    clf.score(X_train, y_train) for clf in clfs\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "clf.score(X_train, y_train) for clf in clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
