{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 (Iterative Dichotomiser 3)\n",
    "\n",
    "C4.5 (successor of ID3)\n",
    "\n",
    "c5.0\n",
    "\n",
    "CART (Classification And Regression Tree)\n",
    "\n",
    "CHAID (CHi-squared Automatic Interaction Detector). ...\n",
    "\n",
    "    MARS: extends decision trees to handle numerical data better. # Not a decision tree\n",
    "\n",
    "    Conditional Inference Trees. # cant find\n",
    "\n",
    "decision stump through adaboosting\n",
    "\n",
    "M5\n",
    "\n",
    "Incremental decision tree\n",
    "\n",
    "Alternating Decision Tree / ADTree\n",
    "\n",
    "----------------------------------------------------\n",
    "\n",
    "Some techniques, often called ensemble methods, construct more than one decision tree:\n",
    "\n",
    "Bagging decision trees / booststrap aggregated, an early ensemble method, builds multiple decision trees by repeatedly re-\n",
    "sampling training data with replacement, and voting the trees for a consensus prediction.\n",
    "\n",
    "A Random Forest classifier / type of bootstrap aggregated  uses a number of decision trees in order to improve the classification rate.\n",
    "\n",
    "Boosted Trees can be used for regression-type and classification-type problems.\n",
    "\n",
    "Rotation forest - in which every decision tree is trained by first applying principal component analysis (PCA) on a random subset of the input features.\n",
    "\n",
    "A special case of a decision tree is a Decision list, which is a one-sided decision tree, so that every internal node has exactly 1 leaf node and exactly 1 internal node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 (Iterative Dichotmiser 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install decision-tree-id3\n",
    "#Documentation https://svaante.github.io/decision-tree-id3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from id3 import Id3Estimator, export_text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id3Estimator(gain_ratio=False, is_repeating=False, max_depth=None,\n",
      "             min_entropy_decrease=0.0, min_samples_split=2, prune=False)\n"
     ]
    }
   ],
   "source": [
    "id3_clf = Id3Estimator(max_depth=None, min_samples_split=2, \n",
    "                     prune=False, gain_ratio=False, min_entropy_decrease=0.0, \n",
    "                     is_repeating=False)\n",
    "\n",
    "clf.fit(X, y, check_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(clf.tree_, feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf.tree_, \"out.dot\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/barisesmer/C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e48abd0cf14c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mC45\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mC45\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC45\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_X' is not defined"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "from C45 import C45\n",
    "\n",
    "c1 = C45(\"../data/iris/iris.data\", \"../data/iris/iris.names\")\n",
    "c1.fetchData()\n",
    "c1.preprocessData()\n",
    "c1.generateTree()\n",
    "c1.printTree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install CHAID\n",
    "#from https://github.com/Rambatino/CHAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CHAID import Tree\n",
    "\n",
    "## create the data\n",
    "ndarr = np.array(([1, 2, 3] * 5) + ([2, 2, 3] * 5)).reshape(10, 3)\n",
    "df = pd.DataFrame(ndarr)\n",
    "df.columns = ['a', 'b', 'c']\n",
    "df['d'] = np.random.normal(300, 100, 10)\n",
    "independent_variable_columns = ['a', 'b', 'c']\n",
    "dep_variable = 'd'\n",
    "\n",
    ">>> df\n",
    "   a  b  c           d\n",
    "0  1  2  3  262.816747\n",
    "1  1  2  3  240.139085\n",
    "2  1  2  3  204.224083\n",
    "3  1  2  3  231.024752\n",
    "4  1  2  3  263.176338\n",
    "5  2  2  3  440.371621\n",
    "6  2  2  3  221.762452\n",
    "7  2  2  3  197.290268\n",
    "8  2  2  3  275.925549\n",
    "9  2  2  3  238.471850\n",
    "\n",
    "## create the Tree via pandas\n",
    "tree = Tree.from_pandas_df(df, dict(zip(independent_variable_columns, ['nominal'] * 3)), dep_variable, dep_variable_type='continuous')\n",
    "\n",
    "## print the tree (though not enough power to split)\n",
    ">>> tree.print_tree()\n",
    "([], {'s.t.d': 86.562258585515579, 'mean': 297.52027436303212}, <Invalid Chaid Split>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.tree_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this exports tree to dot\n",
    "tree.to_tree()\n",
    "#This creates a treelib which has a .to_graphviz() method here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can export the tree to .gv and png using:\n",
    "tree.render(path=None, view=False) #set to true for image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Inference Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rmill040/citrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision stump through Ada-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for label in dataset.columns:\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
    "    \n",
    "X = dataset.drop(['target'],axis=1)\n",
    "Y = dataset['target']\n",
    "\n",
    "#model = DecisionTreeClassifier(criterion='entropy',max_depth=1)\n",
    "#AdaBoost = AdaBoostClassifier(base_estimator= model,n_estimators=400,learning_rate=1)\n",
    "\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "\n",
    "AdaBoost.fit(X,Y)\n",
    "\n",
    "prediction = AdaBoost.score(X,Y)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
